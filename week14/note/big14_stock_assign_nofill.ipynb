{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install finance-datareader"
      ],
      "metadata": {
        "id": "1mANwdx2WvKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR79aQGbV2Uo"
      },
      "outputs": [],
      "source": [
        "import FinanceDataReader as fdr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "samsung = fdr.DataReader('005930', '2016')\n",
        "\n",
        "\n",
        "print(samsung)\n",
        "\n",
        "openValues = samsung[['Open']]\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "scaled = scaler.fit_transform(openValues)\n",
        "\n",
        "TEST_SIZE = 200\n",
        "train_data = scaled[:-TEST_SIZE]\n",
        "test_data = scaled[-TEST_SIZE:]\n",
        "\n",
        "\n",
        "def make_sample(data, window):\n",
        "    train = []\n",
        "    target = []\n",
        "    for i in range(len(data)-window):\n",
        "        train.append(data[i:i+window])\n",
        "        target.append(data[i+window])\n",
        "    return np.array(train), np.array(target)\n",
        "\n",
        "X_train, y_train = make_sample(train_data, 30)\n",
        "\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import LSTM\n",
        "from tensorflow.python.keras.layers import SimpleRNN\n",
        "import tensorflow.python.keras.losses as losses\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(16, \n",
        "                input_shape=(X_train.shape[1], 1), \n",
        "                activation='tanh', \n",
        "                return_sequences=False)\n",
        "          )\n",
        "model.add(Dense(1))\n",
        "\n",
        "#model.add(SimpleRNN(16, activation='tanh', input_shape=(X_train.shape[1], 1)))\n",
        "#model.add(Dense(1))\n",
        "\n",
        "#model.add(SimpleRNN(16, activation='tanh', return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "#model.add(SimpleRNN(20))\n",
        "#model.add(Dense(1))\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs = 100, batch_size = 16)\n",
        "\n",
        "X_test, y_test = make_sample(test_data, 30)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(y_test*scaler.data_max_, label='stock price')\n",
        "plt.plot(pred*scaler.data_max_, label='predicted stock price')\n",
        "print('scale',scaler.data_max_)\n",
        "pred_n=pred*scaler.data_max_\n",
        "y_test_n=y_test*scaler.data_max_\n",
        "print('# RMSE ',np.mean(losses.mean_squared_error(pred_n,y_test_n)**0.5))\n",
        "print('# X_train y_train shape',X_train.shape,y_train.shape)\n",
        "print('# X_test y_test shape',X_test.shape,y_test.shape)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}